{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUb9pj0ngQQ0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-google-genai langgraph python-dotenv\n",
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"Your API Key\""
      ],
      "metadata": {
        "id": "V7MuYckuPb6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.messages import HumanMessage, AIMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "import os\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-lite\",\n",
        "    temperature=0.7,\n",
        "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
        ")\n",
        "\n",
        "class SimpleKnowledgeBaseTool(BaseTool):\n",
        "    name: str = \"simple_knowledge_base\"\n",
        "    description: str = \"Retrieves basic information about AI concepts.\"\n",
        "\n",
        "    def _run(self, query: str):\n",
        "        knowledge = {\n",
        "            \"MCP\": \"Model Context Protocol (MCP) is an open standard by Anthropic designed to connect AI assistants with external data sources, enabling real-time, context-rich interactions.\",\n",
        "            \"RAG\": \"Retrieval-Augmented Generation (RAG) enhances LLM responses by dynamically retrieving relevant external documents.\"\n",
        "        }\n",
        "        return knowledge.get(query, \"I don't have information on that topic.\")\n",
        "\n",
        "    async def _arun(self, query: str):\n",
        "        return self._run(query)\n",
        "\n",
        "kb_tool = SimpleKnowledgeBaseTool()\n",
        "tools = [kb_tool]\n",
        "graph = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "r40WLYJMQXPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def chat_with_agent():\n",
        "    inputs = {\"messages\": []}\n",
        "\n",
        "    print(\"ðŸ¤– MCP-Like Assistant ready! Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"ðŸ‘‹ Ending chat.\")\n",
        "            break\n",
        "\n",
        "        from langchain.schema.messages import HumanMessage, AIMessage\n",
        "        inputs[\"messages\"].append(HumanMessage(content=user_input))\n",
        "\n",
        "        async for state in graph.astream(inputs, stream_mode=\"values\"):\n",
        "            last_message = state[\"messages\"][-1]\n",
        "            if isinstance(last_message, AIMessage):\n",
        "                print(\"\\nAgent:\", last_message.content)\n",
        "\n",
        "        inputs[\"messages\"] = state[\"messages\"]\n",
        "\n",
        "await chat_with_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHoT-AI8Qen0",
        "outputId": "3b4ffb5d-7381-484f-cf4c-3573058eff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– MCP-Like Assistant ready! Type 'exit' to quit.\n",
            "\n",
            "You: What is MCP?\n",
            "\n",
            "Agent: \n",
            "\n",
            "Agent: Model Context Protocol (MCP) is an open standard by Anthropic designed to connect AI assistants with external data sources, enabling real-time, context-rich interactions.\n",
            "\n",
            "You: exit\n",
            "ðŸ‘‹ Ending chat.\n"
          ]
        }
      ]
    }
  ]
}